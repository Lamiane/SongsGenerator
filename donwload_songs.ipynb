{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- zrobić jakiś indentyfikator na entery i zamieniać \\<br\\> na ten identyfikator, przy ostatecznym wypisywaniu zmieniać identyfikator na entery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic calling is: Smart\n"
     ]
    }
   ],
   "source": [
    "%autocall 1\n",
    "import requests\n",
    "import re\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize.moses import MosesTokenizer\n",
    "import datetime \n",
    "\n",
    "ADRES = \"https://www.tekstowo.pl\"\n",
    "EMPTY_STRING_LENGTH = 6\n",
    "ENTER = \" enterenter \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_song_url_from_line(line):\n",
    "    return re.findall(\"piosenka.+html\", line)[0]\n",
    "\n",
    "def find_all_subpages(html_source):\n",
    "    return [re.findall(\"/piosenki_artysty.+html\",line)[0] \n",
    "            for line in html_source \n",
    "            if 'alfabetycznie' in line and 'strona' in line]\n",
    "\n",
    "def get_songs_urls(artists):\n",
    "    artist_songs = {}\n",
    "    for artist in artists:\n",
    "        artist_url = \"https://www.tekstowo.pl/piosenki_artysty,\"+artist+\".html\"\n",
    "        r = requests.get(artist_url).text.split('\\n')\n",
    "        \n",
    "        subpages = set(find_all_subpages(r))\n",
    "        \n",
    "        songs_urls=set()\n",
    "        for subpage in subpages:\n",
    "            r = requests.get(ADRES+subpage)\n",
    "            not_yet = True\n",
    "            for line in r.text.split('\\n'):\n",
    "                if not_yet and 'przeboje' not in line:\n",
    "                    continue\n",
    "                not_yet=False\n",
    "                if 'html' in line and artist in line.lower() and 'piosenka' in line:\n",
    "                        songs_urls.add(ADRES + '/' + extract_song_url_from_line(line.strip()))\n",
    "        \n",
    "        artist_songs[artist]=songs_urls\n",
    "    return artist_songs               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_songs_urls(['enej', 'lzy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_lyrics(urls):\n",
    "    polisher = lambda x: x.encode('iso-8859-1').decode('utf-8')\n",
    "\n",
    "    songs = []\n",
    "    for url in urls:\n",
    "#         print 'parsing', url\n",
    "        html_source = requests.get(url).text\n",
    "        not_yet = True\n",
    "        no_more = False\n",
    "        lyrics = []\n",
    "        for line in html_source.split('\\n'):\n",
    "            if 'song-text' in line:\n",
    "                not_yet = False\n",
    "            if not not_yet and 'javascript' in line:\n",
    "                no_more = True\n",
    "            if not not_yet and not no_more and len(line)>EMPTY_STRING_LENGTH:\n",
    "                try :\n",
    "                    lyrics.append(polisher(line.strip()).replace('<br />', ENTER).lower())\n",
    "                except UnicodeDecodeError:\n",
    "                    print line, line.__repr__()\n",
    "        songs.append('\\n'.join(lyrics[2:-2]))\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'mam tego do\\u015b\\u0107! enterenter\\nmam tego do\\u015b\\u0107! enterenter\\ni zn\\xf3w si\\u0119 rozgl\\u0105dasz, enterenter\\nu\\u015bmiechasz do kogo\\u015b - enterenter\\njeste\\u015b niemo\\u017cliwa wprost! enterenter\\ntak jakbym nie istnia\\u0142 enterenter\\ni nie sta\\u0142 tu\\u017c obok. enterenter\\nprzesta\\u0144 wodzi\\u0107 mnie za nos! enterenter\\nenterenter\\nmam tego do\\u015b\\u0107! enterenter\\nmam tego do\\u015b\\u0107! enterenter\\nzn\\xf3w siedzisz w jakiego\\u015b enterenter\\ngwiazdora wpatrzona, enterenter\\nzas\\u0142uchana w jego g\\u0142os. enterenter\\ni marzysz na pewno enterenter\\no jego ramionach; enterenter\\nfilmu mam ju\\u017c tak\\u017ce do\\u015b\\u0107! enterenter\\nenterenter\\nenterenter\\nmam tego do\\u015b\\u0107! enterenter\\nmam tego do\\u015b\\u0107! enterenter\\ndzi\\u015b rzuc\\u0119 to wszystko enterenter\\ni p\\xf3jd\\u0119 w \\u015bwiat sobie, enterenter\\npotem mnie o powr\\xf3t pro\\u015b. enterenter\\nnie b\\u0119d\\u0119 si\\u0119 waha\\u0142 enterenter\\ni zaraz to zrobi\\u0119; enterenter\\ngorszy mnie nie spotka los. enterenter\\nenterenter\\nno, nie b\\u0105d\\u017a z\\u0142a! enterenter\\nwiem, \\u017ce masz do\\u015b\\u0107, enterenter\\nlecz, widzisz, dziewczyno, enterenter\\nwybra\\u0142a\\u015b mnie sama, enterenter\\nwi\\u0119c humory moje zno\\u015b. enterenter\\nju\\u017c trudno, dziewczyno, enterenter\\nwybra\\u0142a\\u015b mnie sama, enterenter\\nwi\\u0119c humory moje zno\\u015b. enterenter\\nenterenter']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = 'https://www.tekstowo.pl/piosenka,czerwone_gitary,przesta__wodzic_mnie_za_nos.html'\n",
    "extract_lyrics([html,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-25 14:00:39.035371 enej\n",
      "2017-11-25 14:01:40.727773 lzy\n",
      "2017-11-25 14:03:16.036518 happysad\n",
      "2017-11-25 14:04:42.258363 kayah\n",
      "u'\\xc5\\xbbe wci\\xc4\\x85\\xc5\\xbc szumisz tylko pustk\\xc4\\x85\\r'\n",
      "u'bo nie ludzie s\\xc5\\x82owa, ale s\\xc5\\x82owa ludzi nios\\xc4\\x85\\r'\n",
      "2017-11-25 14:06:26.773209 czerwone_gitary\n",
      "2017-11-25 14:09:39.330373 pidzama_porno\n",
      "u'kt\\xc3\\xb3re szybko odje\\xc5\\xbcd\\xc5\\xbcaj\\xc4\\x85\\r'\n",
      "u'Jedn\\xc4\\x85 spocon\\xc4\\x85 noc\\xc4\\x85\\r'\n",
      "2017-11-25 14:11:07.568686 krzysztof_krawczyk\n",
      "u'Co nam do dzisiaj brzmi\\xc4\\x85\\r'\n",
      "u'Cuda, cuda og\\xc5\\x82aszaj\\xc4\\x85\\r'\n",
      "u'nie by\\xc5\\x82o, nigdy nie, nie by\\xc5\\x82o tak.\\xc2\\xa0\\r'\n",
      "2017-11-25 14:13:34.856864 stare_dobre_malze_stwo\n",
      "u'nad Krak\\xc3\\xb3w i wie\\xc5\\xbc\\xc4\\x99 Mariack\\xc4\\x85\\r'\n",
      "u'zn\\xc3\\xb3w zej\\xc5\\x9b\\xc4\\x87 na nasz\\xc4\\x85 ziemi\\xc4\\x99 \\xc5\\x9bwi\\xc4\\x99t\\xc4\\x85\\r'\n",
      "u'Anio\\xc5\\x82y na poddaszu p\\xc5\\x82acz\\xc4\\x85\\r'\n",
      "u'grzesznic\\xc4\\x85 czy \\xc5\\x9bwi\\xc4\\x99t\\xc4\\x85\\r'\n",
      "2017-11-25 14:16:13.175279 zabili_mi_zolwia\n",
      "2017-11-25 14:17:05.402379 elektryczne_gitary\n",
      "2017-11-25 14:19:04.610749 monika_brodka\n",
      "2017-11-25 14:19:52.848121 hey\n",
      "u'Z pi\\xc4\\x85tku na sobot\\xc4\\x99 noc\\xc4\\x85\\r'\n",
      "2017-11-25 14:22:02.057486 gaba_kulka\n",
      "u'zabior\\xc4\\x99 was ze sob\\xc4\\x85\\r'\n",
      "2017-11-25 14:22:43.989028 coma\n",
      "u'[4x]Woda le\\xc5\\xbcy pod powierzchni\\xc4\\x85, powierzchni\\xc4\\x85, pod powierzchni\\xc4\\x85\\r'\n",
      "2017-11-25 14:24:37.000846 ryszard_rynkowski\n",
      "2017-11-25 14:25:42.331783 natalia_kukulska\n",
      "u'A lale ta\\xc5\\x84czy\\xc4\\x87 chc\\xc4\\x85\\r'\n",
      "u'Ja b\\xc4\\x99d\\xc4\\x99 tob\\xc4\\x85 ty mn\\xc4\\x85\\r'\n",
      "u'by ka\\xc5\\xbcdy z nas powiedzie\\xc4\\x87 m\\xc3\\xb3g\\xc5\\x82, \\xc5\\xbce z kumk\\xc4\\x85 by\\xc5\\x82 i gumk\\xc4\\x85\\r'\n"
     ]
    }
   ],
   "source": [
    "def download_lyrics(artists):\n",
    "    song_book = {}\n",
    "    for artist in artists:\n",
    "        print datetime.datetime.now(), artist\n",
    "        song_book[artist] = extract_lyrics(get_songs_urls([artist,])[artist])\n",
    "    return song_book\n",
    "\n",
    "dataset_orig = download_lyrics(['enej', 'lzy', 'happysad', 'kayah', 'czerwone_gitary',\n",
    "                                'pidzama_porno', 'krzysztof_krawczyk', 'stare_dobre_malze_stwo',\n",
    "                                'zabili_mi_zolwia', 'elektryczne_gitary', 'monika_brodka',\n",
    "                                'hey', 'gaba_kulka', 'coma', 'ryszard_rynkowski', 'natalia_kukulska'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_from_file(filepaths, identifiers):\n",
    "    dataset = {}\n",
    "    for filepath, identifier in zip(filepaths, identifiers):\n",
    "        with open(filepath, 'r') as f:\n",
    "            content = f.read()\n",
    "#         dataset[identifier] = polisher(content.strip()).replace('\\n', ENTER).lower()\n",
    "        encoder = lambda x: x.decode('utf-8')\n",
    "        dataset[identifier] = [encoder(content.strip().replace('\\n', ENTER).lower()),]\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mick = get_data_from_file(['mickiewicz.txt'], ['mickiewicz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data_dict, ngram=3):\n",
    "    # zwraca listę z piosenkami, każda piosenka to lista ngramów, ngramy to tuple\n",
    "    dataset = []\n",
    "    tokeniser = MosesTokenizer()\n",
    "    for band in data_dict:\n",
    "        for i in range(len(data_dict[band])):\n",
    "            song = tokeniser.tokenize(data_dict[band][i], return_str=False)\n",
    "            n_song = list(ngrams(song, ngram))\n",
    "            dataset.append(n_song)\n",
    "    return dataset\n",
    "\n",
    "# small = {}\n",
    "# small['e'] = dataset_orig['enej'][2:4]\n",
    "dataset = preprocess(dataset_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_markov(dataset):\n",
    "    mm={}\n",
    "    for song in dataset:\n",
    "        for i in range(len(song)-1):\n",
    "            current = song[i]\n",
    "            following = song[i+1]\n",
    "            if current not in mm:\n",
    "                mm[current]={}\n",
    "            if following not in mm[current]:\n",
    "                mm[current][following] = 0\n",
    "            mm[current][following] += 1\n",
    "    return mm\n",
    "\n",
    "mm = populate_markov(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0792972394802\n"
     ]
    }
   ],
   "source": [
    "def how_often_sway_away(markov_model):\n",
    "    alle = 0\n",
    "    fancy = 0\n",
    "    for key in markov_model:\n",
    "        alle += 1\n",
    "        if len(markov_model[key])>=2:\n",
    "            # print mm[key]\n",
    "            fancy += 1\n",
    "\n",
    "    print float(fancy)/alle\n",
    "    \n",
    "how_often_sway_away(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate(model, text = \"to jest\", length=100):\n",
    "    current = tuple(text.split())\n",
    "    tek = ' '.join(current)\n",
    "    try:\n",
    "        for i in range(length):\n",
    "            highest_probability = 0\n",
    "            possibilities = []\n",
    "            for follower in model[current]:\n",
    "                if model[current][follower] == highest_probability:\n",
    "                    possibilities.append(follower)\n",
    "                if model[current][follower] > highest_probability:\n",
    "                    possibilities = [follower, ]\n",
    "            the_chosen_one = possibilities[np.random.randint(len(possibilities))]\n",
    "            tek += ' ' + the_chosen_one[-1]\n",
    "            current = the_chosen_one\n",
    "    except KeyError:\n",
    "        return tek + '\\nKONIEC'\n",
    "    return tek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unlikely_generate(model, text = \"to jest\", length=100):\n",
    "    current = tuple(text.split())\n",
    "    tek=' '.join(current)\n",
    "    try:\n",
    "        for i in range(length):\n",
    "            highest_probability = 0\n",
    "            possibilities = []\n",
    "            for follower in model[current]:\n",
    "                possibilities.append(follower)\n",
    "            the_chosen_one = possibilities[np.random.randint(len(possibilities))]\n",
    "            tek += ' ' + the_chosen_one[-1]\n",
    "            current = the_chosen_one\n",
    "    except KeyError:\n",
    "        return tek + '\\nKONIEC'\n",
    "    return tek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ja i ty ... \n",
      " \n",
      " bądź lekarstwem mym \n",
      " \n",
      " można się kochać \n",
      " będziesz tulił mnie i całował jak dawniej \n",
      " i będę cię prosić , bym mogła zostać do rana \n",
      " wystarczy nam \n",
      " \n",
      " nie musi być też taki przystojny , \n",
      " ale ważne jest to , co najlepszego masz\n",
      " raz ty , raz ja.\n",
      " jeszcze tyle miejsc , gdzie pragną tańczyć.\n",
      " \n",
      " nie zmarnujmy tej ostatniej szansy -\n",
      " koncert musi trwać , nuty trzeba znać\n",
      " i grać , i grać.\n",
      " \n",
      " jeszcze mamy czas uwierzyć w siebie.\n",
      " jeszcze bóg nam da niechciane szczęście.\n",
      " jeszcze drogi dwie , w\n"
     ]
    }
   ],
   "source": [
    "generated =  unlikely_generate(mm, u\"ja i ty\")\n",
    "print generated.replace(ENTER, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dataset.json', 'w') as f:\n",
    "    json.dump(dataset_orig, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0387529266246\n",
      "litwo ! ojczyzno moja ! ty jesteś jak zdrowie.\n",
      "ile cię trzeba cenić , ten tylko się dowie ,\n",
      "kto przypuści do siebie zwierza jak należy ,\n",
      "jeśli chybił , cofnąć się może bez sromoty\n",
      "albo walczyć oszczepem , lecz z miny widać , że mu nawet nie przyszło do głowy ,\n",
      "jako ostatni odbłysk ziemskiej jacka chwały.\n",
      "tymczasem lud na klęczkach anioł pański mowi ,\n",
      "upraszając o wieczny pokój grzesznikowi ;\n",
      "sędzia podkomorzego zdał się radzić okiem ,\n",
      "zdawał się słuchać rozmów , oczy w talerz wlepił ;\n",
      "telimena , zowiąc je\n"
     ]
    }
   ],
   "source": [
    "mick = get_data_from_file(['mickiewicz.txt'], ['mickiewicz'])\n",
    "mick = preprocess(mick, 3)\n",
    "mick_model = populate_markov(mick)\n",
    "how_often_sway_away(mick_model)\n",
    "\n",
    "migrated =  unlikely_generate(mick_model, u\"litwo ! ojczyzno\")\n",
    "print migrated.replace(ENTER, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0701087292976\n"
     ]
    }
   ],
   "source": [
    "two = dict(dataset_orig)\n",
    "two['mick'] = get_data_from_file(['mickiewicz.txt'], ['mickiewicz'])['mickiewicz']\n",
    "\n",
    "two = preprocess(two, 3)\n",
    "two_model = populate_markov(two)\n",
    "how_often_sway_away(two_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litwo ! ojczyzno moja ! ty jesteś jak zdrowie. \n",
      " ile cię trzeba cenić , ten tylko się dowie , \n",
      " kto jej dał patent rosnąć nad wszystkie krzewiny \" . \n",
      " na rozstaju dróg , gdzie przydrożny chrystus stał , \n",
      " powiedz mi o dzika świnio \n",
      " skąd bierzesz słodki cukier swój \n",
      " \n",
      " i zaznamy jeszcze nieba w naszych mordach \n",
      " a gdy będziesz miał kiedyś tyle lat co ja , \n",
      " że wasze myśli razem są , \n",
      " ale za nie piłeś więc \n",
      " żeś wytrzymał istny cud , użyjem w bród ! \n",
      " \n",
      " zapomnieć chcę , \n",
      " tak\n"
     ]
    }
   ],
   "source": [
    "t =  unlikely_generate(two_model, u\"litwo ! ojczyzno\")\n",
    "print t.replace(ENTER.strip(), '\\n').replace('&quot;', '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litwo ! ojczyzno moja ! ty jesteś jak ona .. \n",
      " a życie , jakie życie ? \n",
      " poprzecinana linia na dłoniach \n",
      " a bóg ? nie ma boga. \n",
      "\\KONIEC\n"
     ]
    }
   ],
   "source": [
    "t =  generate(two_model, u\"litwo ! ojczyzno\")\n",
    "print t.replace(ENTER.strip(), '\\n').replace('&quot;', '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
