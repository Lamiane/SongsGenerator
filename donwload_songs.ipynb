{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- zrobić jakiś indentyfikator na entery i zamieniać \\<br\\> na ten identyfikator, przy ostatecznym wypisywaniu zmieniać identyfikator na entery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic calling is: Smart\n"
     ]
    }
   ],
   "source": [
    "%autocall 1\n",
    "import requests\n",
    "import re\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize.moses import MosesTokenizer\n",
    "import datetime \n",
    "\n",
    "ADRES = \"https://www.tekstowo.pl\"\n",
    "EMPTY_STRING_LENGTH = 6\n",
    "ENTER = \"enterenter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_song_url_from_line(line):\n",
    "    return re.findall(\"piosenka.+html\", line)[0]\n",
    "\n",
    "def find_all_subpages(html_source):\n",
    "    return [re.findall(\"/piosenki_artysty.+html\",line)[0] \n",
    "            for line in html_source \n",
    "            if 'alfabetycznie' in line and 'strona' in line]\n",
    "\n",
    "def get_songs_urls(artists):\n",
    "    artist_songs = {}\n",
    "    for artist in artists:\n",
    "        artist_url = \"https://www.tekstowo.pl/piosenki_artysty,\"+artist+\".html\"\n",
    "        r = requests.get(artist_url).text.split('\\n')\n",
    "        \n",
    "        subpages = set(find_all_subpages(r))\n",
    "        \n",
    "        songs_urls=set()\n",
    "        for subpage in subpages:\n",
    "            r = requests.get(ADRES+subpage)\n",
    "            not_yet = True\n",
    "            for line in r.text.split('\\n'):\n",
    "                if not_yet and 'przeboje' not in line:\n",
    "                    continue\n",
    "                not_yet=False\n",
    "                if 'html' in line and artist in line.lower() and 'piosenka' in line:\n",
    "                        songs_urls.add(ADRES + '/' + extract_song_url_from_line(line.strip()))\n",
    "        \n",
    "        artist_songs[artist]=songs_urls\n",
    "    return artist_songs               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_songs_urls(['enej', 'lzy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_lyrics(urls):\n",
    "    polisher = lambda x: x.encode('iso-8859-1').decode('utf-8')\n",
    "    \n",
    "    songs = []\n",
    "    for url in urls:\n",
    "#         print 'parsing', url\n",
    "        html_source = requests.get(url).text\n",
    "        not_yet = True\n",
    "        no_more = False\n",
    "        lyrics = []\n",
    "        for line in html_source.split('\\n'):\n",
    "            if 'song-text' in line:\n",
    "                not_yet = False\n",
    "            if not not_yet and 'javascript' in line:\n",
    "                no_more = True\n",
    "            if not not_yet and not no_more and len(line)>EMPTY_STRING_LENGTH:\n",
    "                try :\n",
    "                    lyrics.append(polisher(line.strip()).replace('<br />', ENTER).lower())\n",
    "                except UnicodeDecodeError:\n",
    "                    print line, line.__repr__()\n",
    "        songs.append('\\n'.join(lyrics[2:-2]))\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'mam tego do\\u015b\\u0107! enterenter\\nmam tego do\\u015b\\u0107! enterenter\\ni zn\\xf3w si\\u0119 rozgl\\u0105dasz, enterenter\\nu\\u015bmiechasz do kogo\\u015b - enterenter\\njeste\\u015b niemo\\u017cliwa wprost! enterenter\\ntak jakbym nie istnia\\u0142 enterenter\\ni nie sta\\u0142 tu\\u017c obok. enterenter\\nprzesta\\u0144 wodzi\\u0107 mnie za nos! enterenter\\nenterenter\\nmam tego do\\u015b\\u0107! enterenter\\nmam tego do\\u015b\\u0107! enterenter\\nzn\\xf3w siedzisz w jakiego\\u015b enterenter\\ngwiazdora wpatrzona, enterenter\\nzas\\u0142uchana w jego g\\u0142os. enterenter\\ni marzysz na pewno enterenter\\no jego ramionach; enterenter\\nfilmu mam ju\\u017c tak\\u017ce do\\u015b\\u0107! enterenter\\nenterenter\\nenterenter\\nmam tego do\\u015b\\u0107! enterenter\\nmam tego do\\u015b\\u0107! enterenter\\ndzi\\u015b rzuc\\u0119 to wszystko enterenter\\ni p\\xf3jd\\u0119 w \\u015bwiat sobie, enterenter\\npotem mnie o powr\\xf3t pro\\u015b. enterenter\\nnie b\\u0119d\\u0119 si\\u0119 waha\\u0142 enterenter\\ni zaraz to zrobi\\u0119; enterenter\\ngorszy mnie nie spotka los. enterenter\\nenterenter\\nno, nie b\\u0105d\\u017a z\\u0142a! enterenter\\nwiem, \\u017ce masz do\\u015b\\u0107, enterenter\\nlecz, widzisz, dziewczyno, enterenter\\nwybra\\u0142a\\u015b mnie sama, enterenter\\nwi\\u0119c humory moje zno\\u015b. enterenter\\nju\\u017c trudno, dziewczyno, enterenter\\nwybra\\u0142a\\u015b mnie sama, enterenter\\nwi\\u0119c humory moje zno\\u015b. enterenter\\nenterenter']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = 'https://www.tekstowo.pl/piosenka,czerwone_gitary,przesta__wodzic_mnie_za_nos.html'\n",
    "extract_lyrics([html,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-24 23:31:48.473570 enej\n",
      "2017-11-24 23:33:05.612320 lzy\n",
      "2017-11-24 23:35:00.887549 happysad\n",
      "2017-11-24 23:36:38.901054 kayah\n",
      "u'\\xc5\\xbbe wci\\xc4\\x85\\xc5\\xbc szumisz tylko pustk\\xc4\\x85\\r'\n",
      "u'bo nie ludzie s\\xc5\\x82owa, ale s\\xc5\\x82owa ludzi nios\\xc4\\x85\\r'\n",
      "2017-11-24 23:38:33.501543 czerwone_gitary\n",
      "2017-11-24 23:41:48.304188 pidzama_porno\n",
      "u'kt\\xc3\\xb3re szybko odje\\xc5\\xbcd\\xc5\\xbcaj\\xc4\\x85\\r'\n",
      "u'Jedn\\xc4\\x85 spocon\\xc4\\x85 noc\\xc4\\x85\\r'\n",
      "2017-11-24 23:43:31.622233 krzysztof_krawczyk\n",
      "u'Co nam do dzisiaj brzmi\\xc4\\x85\\r'\n",
      "u'Cuda, cuda og\\xc5\\x82aszaj\\xc4\\x85\\r'\n",
      "u'nie by\\xc5\\x82o, nigdy nie, nie by\\xc5\\x82o tak.\\xc2\\xa0\\r'\n",
      "2017-11-24 23:46:29.515990 stare_dobre_malze_stwo\n",
      "u'nad Krak\\xc3\\xb3w i wie\\xc5\\xbc\\xc4\\x99 Mariack\\xc4\\x85\\r'\n",
      "u'\\xc5\\xbbe ich \\xc5\\x9blady prosto do nieba prowadz\\xc4\\x85 \\r'\n",
      "u'zn\\xc3\\xb3w zej\\xc5\\x9b\\xc4\\x87 na nasz\\xc4\\x85 ziemi\\xc4\\x99 \\xc5\\x9bwi\\xc4\\x99t\\xc4\\x85\\r'\n",
      "u'Anio\\xc5\\x82y na poddaszu p\\xc5\\x82acz\\xc4\\x85\\r'\n",
      "u'grzesznic\\xc4\\x85 czy \\xc5\\x9bwi\\xc4\\x99t\\xc4\\x85\\r'\n",
      "2017-11-24 23:49:29.286226 zabili_mi_zolwia\n",
      "2017-11-24 23:50:28.695598 elektryczne_gitary\n",
      "2017-11-24 23:52:26.339456 monika_brodka\n",
      "2017-11-24 23:53:16.640816 hey\n",
      "u'Z pi\\xc4\\x85tku na sobot\\xc4\\x99 noc\\xc4\\x85\\r'\n",
      "2017-11-24 23:55:30.126361 gaba_kulka\n",
      "u'zabior\\xc4\\x99 was ze sob\\xc4\\x85\\r'\n",
      "2017-11-24 23:56:14.859847 coma\n",
      "u'[4x]Woda le\\xc5\\xbcy pod powierzchni\\xc4\\x85, powierzchni\\xc4\\x85, pod powierzchni\\xc4\\x85\\r'\n",
      "2017-11-24 23:58:17.015691 ryszard_rynkowski\n",
      "2017-11-24 23:59:36.892060 natalia_kukulska\n",
      "u'A lale ta\\xc5\\x84czy\\xc4\\x87 chc\\xc4\\x85\\r'\n",
      "u'Ja b\\xc4\\x99d\\xc4\\x99 tob\\xc4\\x85 ty mn\\xc4\\x85\\r'\n",
      "u'by ka\\xc5\\xbcdy z nas powiedzie\\xc4\\x87 m\\xc3\\xb3g\\xc5\\x82, \\xc5\\xbce z kumk\\xc4\\x85 by\\xc5\\x82 i gumk\\xc4\\x85\\r'\n"
     ]
    }
   ],
   "source": [
    "def download_lyrics(artists):\n",
    "    song_book = {}\n",
    "    for artist in artists:\n",
    "        print datetime.datetime.now(), artist\n",
    "        song_book[artist] = extract_lyrics(get_songs_urls([artist,])[artist])\n",
    "    return song_book\n",
    "\n",
    "dataset_orig = download_lyrics(['enej', 'lzy', 'happysad', 'kayah', 'czerwone_gitary',\n",
    "                                'pidzama_porno', 'krzysztof_krawczyk', 'stare_dobre_malze_stwo',\n",
    "                                'zabili_mi_zolwia', 'elektryczne_gitary', 'monika_brodka',\n",
    "                                'hey', 'gaba_kulka', 'coma', 'ryszard_rynkowski', 'natalia_kukulska'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_dict, ngram=3):\n",
    "    # zwraca listę z piosenkami, każda piosenka to lista ngramów, ngramy to tuple\n",
    "    dataset = []\n",
    "    tokeniser = MosesTokenizer()\n",
    "    for band in data_dict:\n",
    "        for i in range(len(data_dict[band])):\n",
    "            song = tokeniser.tokenize(data_dict[band][i], return_str=False)\n",
    "            n_song = list(ngrams(song, ngram))\n",
    "            dataset.append(n_song)\n",
    "    return dataset\n",
    "\n",
    "# small = {}\n",
    "# small['e'] = dataset_orig['enej'][2:4]\n",
    "dataset = preprocess(dataset_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_markov(dataset):\n",
    "    mm={}\n",
    "    for song in dataset:\n",
    "        for i in range(len(song)-1):\n",
    "            current = song[i]\n",
    "            following = song[i+1]\n",
    "            if current not in mm:\n",
    "                mm[current]={}\n",
    "            if following not in mm[current]:\n",
    "                mm[current][following] = 0\n",
    "            mm[current][following] += 1\n",
    "    return mm\n",
    "\n",
    "mm = populate_markov(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0639950780081\n"
     ]
    }
   ],
   "source": [
    "alle = 0\n",
    "fancy = 0\n",
    "for key in mm:\n",
    "    alle += 1\n",
    "    if len(mm[key])>=2:\n",
    "        # print mm[key]\n",
    "        fancy += 1\n",
    "            \n",
    "print float(fancy)/alle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate(model, text = \"to jest\", length=100):\n",
    "    current = tuple(text.split())\n",
    "    for i in range(length):\n",
    "        highest_probability = 0\n",
    "        possibilities = []\n",
    "        for follower in model[current]:\n",
    "            if model[current][follower] == highest_probability:\n",
    "                possibilities.append(follower)\n",
    "            if model[current][follower] > highest_probability:\n",
    "                possibilities = [follower, ]\n",
    "        the_chosen_one = possibilities[np.random.randint(len(possibilities))]\n",
    "        print the_chosen_one[-1]\n",
    "        current = the_chosen_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unlikely_generate(model, text = \"to jest\", length=100):\n",
    "    current = tuple(text.split())\n",
    "    tek=' '.join(current)\n",
    "    try:\n",
    "        for i in range(length):\n",
    "            highest_probability = 0\n",
    "            possibilities = []\n",
    "            for follower in model[current]:\n",
    "                possibilities.append(follower)\n",
    "            the_chosen_one = possibilities[np.random.randint(len(possibilities))]\n",
    "            tek+= ' ' + the_chosen_one[-1]\n",
    "            current = the_chosen_one\n",
    "    except KeyError:\n",
    "        return tek\n",
    "    return tek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ja i ty ... \n",
      " \n",
      " bądź lekarstwem mym \n",
      " \n",
      " można się kochać \n",
      " będziesz tulił mnie i całował jak dawniej \n",
      " i będę cię prosić , bym mogła zostać do rana \n",
      " wystarczy nam \n",
      " \n",
      " nie musi być też taki przystojny , \n",
      " ale ważne jest to , co najlepszego masz\n",
      " raz ty , raz ja.\n",
      " jeszcze tyle miejsc , gdzie pragną tańczyć.\n",
      " \n",
      " nie zmarnujmy tej ostatniej szansy -\n",
      " koncert musi trwać , nuty trzeba znać\n",
      " i grać , i grać.\n",
      " \n",
      " jeszcze mamy czas uwierzyć w siebie.\n",
      " jeszcze bóg nam da niechciane szczęście.\n",
      " jeszcze drogi dwie , w\n"
     ]
    }
   ],
   "source": [
    "generated =  unlikely_generate(mm, u\"ja i ty\")\n",
    "print generated.replace(ENTER, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dataset.json', 'w') as f:\n",
    "    json.dump(dataset_orig, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
